{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ade48cb-cf90-41c0-aa08-eb4b3f0f5840",
   "metadata": {},
   "source": [
    "# Create Google ADK EvalSet from Chat Logs\n",
    "\n",
    "**Objective:** This notebook processes a raw chat log CSV, identifies conversation sessions, and uses the Gemini 2.5 Pro model to generate a structured Google Agent Development Kit (ADK) EvalSet JSON.\n",
    "\n",
    "---\n",
    "\n",
    "### Technical Workflow\n",
    "\n",
    "1.  **Session Identification (Pandas):**\n",
    "    *   Loads `chats.csv`.\n",
    "    *   Identifies sessions based on `User in Session` and a 30-minute inactivity threshold.\n",
    "    *   Assigns a unique `session_id` to each session.\n",
    "    *   Saves the processed DataFrame to `chats_with_sessions.csv`.\n",
    "\n",
    "2.  **ADK EvalSet Generation (google-genai):**\n",
    "    *   Constructs a prompt with the sessionized data and a target ADK JSON schema.\n",
    "    *   Calls the Gemini model to convert the tabular data into a structured JSON.\n",
    "    *   Saves the final, validated output to `gemini_response.json`.\n",
    "\n",
    "### I/O\n",
    "*   **Input:** `chats.csv`\n",
    "*   **Output:** `gemini_response.json`\n",
    "\n",
    "Disclaimer: This is not an official Google service/product and is intended for reference purposes only. Do not use in a production environment.\n",
    "\n",
    "Questions ? mateuswagner@google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867dc44-2654-4bad-ad64-221766b41eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08858f7-f4c8-458a-83d8-26ec63ed060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import HttpOptions\n",
    "import base64\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import timedelta\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7606a7e-8819-46c8-83b1-5d5c4c832f78",
   "metadata": {},
   "source": [
    "### **Define Model Configuration and Prompts for EvalSet Generation**\n",
    "\n",
    "This cell sets up the configuration for a `gemini-2.5-pro` model. It defines two key prompts:\n",
    "\n",
    "1.  `sys_prompt`: Sets the model's persona to be an expert in Google's Agent Development Kit (ADK).\n",
    "2.  `create_evalset_prompt`: Provides detailed instructions for the model to convert agent chat logs from a pandas DataFrame into a structured JSON file compliant with the ADK `EvalSet` schema. This format is used for evaluating the performance of AI agents.\n",
    "\n",
    "It also configures the model to use `gemini-2.5-pro` and disables all safety settings for the generation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbec4f-4f5e-4fa4-8011-2d16ccd91d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"You are an expert developer specializing in Google's Agent Development Kit (ADK).\"\"\"\n",
    "\n",
    "create_evalset_prompt = \"\"\"\n",
    "Your sole function is to convert the agent chat logs into a single, complete, and perfectly valid json string compliant with the Google ADK EvalSet schema.\n",
    "\n",
    "Critical Requirements:\n",
    "\n",
    "json-Only Output: Your entire response MUST be the raw json content. Do not include any explanations, introductory text, or markdown code fences (like ```json).\n",
    "Strict Schema Adherence: The output MUST be a valid ADK EvalSet. Include ALL required schema fields, even if it means generating plausible placeholder data for fields not present in the source DataFrame.\n",
    "Chronological Integrity: Messages within each conversation MUST be maintained in their exact original chronological order.\n",
    "Content Preservation: The text from the MESSAGE column MUST be preserved verbatim. Do not summarize, alter, or rephrase any message content.\n",
    "Unique ID Generation: Generate a unique identifier for the top-level eval_set_id and for every invocation_id field within the conversations.\n",
    "Graceful Edge Case Handling: If the input DataFrame is empty, output a valid json structure with an empty eval_cases list. If a session is incomplete, process the turns that are present. The output must always be valid json.\n",
    "\n",
    "Input Source:\n",
    "A pandas DataFrame with the columns: User in Session, ROLE, MESSAGE.\n",
    "\n",
    "Conversion Logic:\n",
    "Session Grouping: Group the DataFrame by User in Session. Each unique session maps to a single eval_case object.\n",
    "Turn Processing: Within each session, process messages chronologically to build the conversation list. A turn consists of a user's message and all subsequent model messages before the next user input.\n",
    "Role Mapping & Content Analysis:\n",
    "If ROLE is 'user': Map the MESSAGE to the user_content.parts.text field.\n",
    "If ROLE is 'model': Analyze the MESSAGE content to determine its type:\n",
    "Tool Call: If the message indicates a function call (contains function names, parameters, etc.), structure it as an entry in the intermediate_data.tool_uses list, correctly extracting the tool name and args.\n",
    "Final Response: If the message is the concluding natural language answer for that turn, map it to the final_response.parts.text field.\n",
    "Metadata Population:\n",
    "Use the User in Session value as the eval_id for its corresponding eval_case.\n",
    "Populate session_input with appropriate placeholder data (e.g., app_name: \"my_agent\", user_id: \"test_user\").\n",
    "Use \"role\": \"user\" or \"model\"\n",
    "\n",
    "Task:\n",
    "Process the provided logs and convert it to a complete, valid ADK EvalSet json file according to all requirements and logic specified above.\n",
    "\n",
    "\n",
    "Example of Evalset:\n",
    "# Do note that some fields are removed for sake of making this doc readable.\n",
    "{\n",
    "  \"eval_set_id\": \"eval_set_example_with_multiple_sessions\",\n",
    "  \"name\": \"Eval set with multiple sessions\",\n",
    "  \"description\": \"This eval set is an example that shows that an eval set can have more than one session.\",\n",
    "  \"eval_cases\": [\n",
    "    {\n",
    "      \"eval_id\": \"session_01\",\n",
    "      \"conversation\": [\n",
    "        {\n",
    "          \"invocation_id\": \"e-0067f6c4-ac27-4f24-81d7-3ab994c28768\",\n",
    "          \"user_content\": {\n",
    "            \"parts\": [\n",
    "              {\n",
    "                \"text\": \"What can you do?\"\n",
    "              }\n",
    "            ],\n",
    "            \"role\": \"user\"\n",
    "          },\n",
    "          \"final_response\": {\n",
    "            \"parts\": [\n",
    "              {\n",
    "\n",
    "                \"text\": \"I can roll dice of different sizes and check if numbers are prime.\"\n",
    "              }\n",
    "            ],\n",
    "            \"role\": null\n",
    "          },\n",
    "          \"intermediate_data\": {\n",
    "            \"tool_uses\": [],\n",
    "            \"intermediate_responses\": []\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "      \"session_input\": {\n",
    "        \"app_name\": \"hello_world\",\n",
    "        \"user_id\": \"user\",\n",
    "        \"state\": {}\n",
    "      },\n",
    "    },\n",
    "    {\n",
    "      \"eval_id\": \"session_02\",\n",
    "      \"conversation\": [\n",
    "        {\n",
    "          \"invocation_id\": \"e-92d34c6d-0a1b-452a-ba90-33af2838647a\",\n",
    "          \"user_content\": {\n",
    "            \"parts\": [\n",
    "              {\n",
    "                \"text\": \"Roll a 19 sided dice\"\n",
    "              }\n",
    "            ],\n",
    "            \"role\": \"user\"\n",
    "          },\n",
    "          \"final_response\": {\n",
    "            \"parts\": [\n",
    "              {\n",
    "                \"text\": \"I rolled a 17.\"\n",
    "              }\n",
    "            ],\n",
    "            \"role\": null\n",
    "          },\n",
    "          \"intermediate_data\": {\n",
    "            \"tool_uses\": [],\n",
    "            \"intermediate_responses\": []\n",
    "          },\n",
    "        },\n",
    "        {\n",
    "          \"invocation_id\": \"e-bf8549a1-2a61-4ecc-a4ee-4efbbf25a8ea\",\n",
    "          \"user_content\": {\n",
    "            \"parts\": [\n",
    "              {\n",
    "                \"text\": \"Roll a 10 sided dice twice and then check if 9 is a prime or not\"\n",
    "              }\n",
    "            ],\n",
    "            \"role\": \"user\"\n",
    "          },\n",
    "          \"final_response\": {\n",
    "            \"parts\": [\n",
    "              {\n",
    "                \"text\": \"I got 4 and 7 from the dice roll, and 9 is not a prime number.\\n\"\n",
    "              }\n",
    "            ],\n",
    "            \"role\": null\n",
    "          },\n",
    "          \"intermediate_data\": {\n",
    "            \"tool_uses\": [\n",
    "              {\n",
    "                \"id\": \"adk-1a3f5a01-1782-4530-949f-07cf53fc6f05\",\n",
    "                \"args\": {\n",
    "                  \"sides\": 10\n",
    "                },\n",
    "                \"name\": \"roll_die\"\n",
    "              },\n",
    "              {\n",
    "                \"id\": \"adk-52fc3269-caaf-41c3-833d-511e454c7058\",\n",
    "                \"args\": {\n",
    "                  \"sides\": 10\n",
    "                },\n",
    "                \"name\": \"roll_die\"\n",
    "              },\n",
    "              {\n",
    "                \"id\": \"adk-5274768e-9ec5-4915-b6cf-f5d7f0387056\",\n",
    "                \"args\": {\n",
    "                  \"nums\": [\n",
    "                    9\n",
    "                  ]\n",
    "                },\n",
    "                \"name\": \"check_prime\"\n",
    "              }\n",
    "            ],\n",
    "            \"intermediate_responses\": [\n",
    "              [\n",
    "                \"data_processing_agent\",\n",
    "                [\n",
    "                  {\n",
    "                    \"text\": \"I have rolled a 10 sided die twice. The first roll is 5 and the second roll is 3.\\n\"\n",
    "                  }\n",
    "                ]\n",
    "              ]\n",
    "            ]\n",
    "          },\n",
    "        }\n",
    "      ],\n",
    "      \"session_input\": {\n",
    "        \"app_name\": \"hello_world\",\n",
    "        \"user_id\": \"user\",\n",
    "        \"state\": {}\n",
    "      },\n",
    "    }\n",
    "  ],\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "model = \"gemini-2.5-pro\"\n",
    "safety_settings = [\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "        types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8fd25-8afb-436a-a4c3-253ec420e2b7",
   "metadata": {},
   "source": [
    "# Identify and Assign Chat Session IDs\n",
    "This script reads a chat log from `INPUT_FILE`, groups messages into sessions for each user, and assigns a unique `session_id`. A new session begins when the time between a user's consecutive messages exceeds the `TIME_GAP_MINUTES` threshold. The processed data, including the new `session_id` column, is saved to `OUTPUT_FILE`.\n",
    "\n",
    "Columns:\n",
    "\n",
    "- date: Timestamp of the message.\n",
    "\n",
    "- User in Session: The user's name.\n",
    "\n",
    "- ROLE: Role of the message sender (user or assistant).\n",
    "\n",
    "- MESSAGE: The content of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c718cff-6a90-4ae7-baae-c8a31619d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_FILE = \"chats.csv\"\n",
    "OUTPUT_FILE = \"chats_with_sessions.csv\"\n",
    "TIME_GAP_MINUTES = 30\n",
    "random.seed(42)\n",
    "\n",
    "def process_chat_sessions(file_path, time_gap_minutes=30):\n",
    "    \"\"\"Process chat data to identify sessions and assign unique IDs.\"\"\"\n",
    "    \n",
    "    # Load and validate data\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        required_cols = ['date', 'User in Session', 'ROLE', 'MESSAGE']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            raise ValueError(f\"Missing required columns: {required_cols}\")\n",
    "        \n",
    "        if df.empty:\n",
    "            df['session_id'] = pd.Series(dtype='int64')\n",
    "            return df\n",
    "            \n",
    "        print(f\"Loaded {len(df)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Preprocess data\n",
    "    df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "    df = df.sort_values(['User in Session', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # Initialize session tracking\n",
    "    session_ids = []\n",
    "    used_ids = set()\n",
    "    \n",
    "    # Process each user's messages\n",
    "    for user, user_group in df.groupby('User in Session'):\n",
    "        user_group = user_group.sort_values('date').reset_index(drop=True)\n",
    "        time_diffs = user_group['date'].diff()\n",
    "        current_session = None\n",
    "        \n",
    "        for idx in range(len(user_group)):\n",
    "            # Start new session if: first message OR time gap > threshold\n",
    "            if idx == 0 or (pd.notna(time_diffs.iloc[idx]) and \n",
    "                           time_diffs.iloc[idx] > timedelta(minutes=time_gap_minutes)):\n",
    "                # Generate unique 8-digit session ID\n",
    "                while True:\n",
    "                    current_session = random.randint(10000000, 99999999)\n",
    "                    if current_session not in used_ids:\n",
    "                        used_ids.add(current_session)\n",
    "                        break\n",
    "            \n",
    "            session_ids.append(current_session)\n",
    "    \n",
    "    # Add session_id column after date\n",
    "    df['session_id'] = session_ids\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('session_id')\n",
    "    date_idx = cols.index('date')\n",
    "    cols.insert(date_idx + 1, 'session_id')\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute processing\n",
    "try:\n",
    "    result_df = process_chat_sessions(INPUT_FILE, TIME_GAP_MINUTES)\n",
    "    \n",
    "    if result_df is not None:\n",
    "        # Save results\n",
    "        result_df.to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        # Display summary\n",
    "        print(f\"\\nProcessing completed!\")\n",
    "        print(f\"Sessions identified: {result_df['session_id'].nunique()}\")\n",
    "        print(f\"Users processed: {result_df['User in Session'].nunique()}\")\n",
    "        print(f\"Output saved to: {OUTPUT_FILE}\")\n",
    "        \n",
    "        # Show sample\n",
    "        print(f\"\\nSample output:\")\n",
    "        print(result_df[['date', 'session_id', 'User in Session', 'ROLE', 'MESSAGE']].head(10))\n",
    "        \n",
    "        # Validation\n",
    "        sessions_per_user = result_df.groupby('session_id')['User in Session'].nunique()\n",
    "        if (sessions_per_user == 1).all():\n",
    "            print(\"Validation passed: All sessions belong to single users\")\n",
    "        else:\n",
    "            print(\"Warning: Some sessions span multiple users\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ed2aa-199c-46eb-895c-055bc249a20d",
   "metadata": {},
   "source": [
    "### Evaluation Dataset Schema\n",
    "This JSON schema defines the structure for a model evaluation dataset. It contains a set of evaluation cases (`eval_cases`), where each case captures a complete multi-turn `conversation`. Each turn in the conversation includes the user's input, the model's final response, and any intermediate `tool_uses` and their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd659746-f913-4d77-9e5e-986861a0efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schema = {\n",
    "  \"type\": \"OBJECT\",\n",
    "  \"properties\": {\n",
    "    \"eval_set_id\": {\"type\": \"STRING\"},\n",
    "    \"name\": {\"type\": \"STRING\"},\n",
    "    \"description\": {\"type\": \"STRING\"},\n",
    "    \"eval_cases\": {\n",
    "      \"type\": \"ARRAY\",\n",
    "      \"items\": {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "          \"eval_id\": {\"type\": \"STRING\"},\n",
    "          \"conversation\": {\n",
    "            \"type\": \"ARRAY\",\n",
    "            \"items\": {\n",
    "              \"type\": \"OBJECT\",\n",
    "              \"properties\": {\n",
    "                \"invocation_id\": {\"type\": \"STRING\"},\n",
    "                \"user_content\": {\n",
    "                  \"type\": \"OBJECT\",\n",
    "                  \"properties\": {\n",
    "                    \"parts\": {\n",
    "                      \"type\": \"ARRAY\",\n",
    "                      \"items\": {\n",
    "                        \"type\": \"OBJECT\",\n",
    "                        \"properties\": {\n",
    "                          \"text\": {\"type\": \"STRING\"}\n",
    "                        },\n",
    "                        \"required\": [\"text\"]\n",
    "                      }\n",
    "                    },\n",
    "                    \"role\": {\"type\": \"STRING\"}\n",
    "                  },\n",
    "                  \"required\": [\"parts\", \"role\"]\n",
    "                },\n",
    "                \"final_response\": {\n",
    "                  \"type\": \"OBJECT\",\n",
    "                  \"properties\": {\n",
    "                    \"parts\": {\n",
    "                      \"type\": \"ARRAY\",\n",
    "                      \"items\": {\n",
    "                        \"type\": \"OBJECT\",\n",
    "                        \"properties\": {\n",
    "                          \"text\": {\"type\": \"STRING\"}\n",
    "                        },\n",
    "                        \"required\": [\"text\"]\n",
    "                      }\n",
    "                    },\n",
    "                    \"role\": {\"type\": \"STRING\"}\n",
    "                  },\n",
    "                  \"required\": [\"parts\"]\n",
    "                },\n",
    "                \"intermediate_data\": {\n",
    "                  \"type\": \"OBJECT\",\n",
    "                  \"properties\": {\n",
    "                    \"tool_uses\": {\n",
    "                      \"type\": \"ARRAY\",\n",
    "                      \"items\": {\n",
    "                        \"type\": \"OBJECT\",\n",
    "                        \"properties\": {\n",
    "                          \"id\": {\"type\": \"STRING\"},\n",
    "                          \"args\": {\"type\": \"OBJECT\"},\n",
    "                          \"name\": {\"type\": \"STRING\"}\n",
    "                        },\n",
    "                        \"required\": [\"id\", \"args\", \"name\"]\n",
    "                      }\n",
    "                    },\n",
    "                    \"intermediate_responses\": {\n",
    "                      \"type\": \"ARRAY\",\n",
    "                      \"items\": {\n",
    "                        \"type\": \"ARRAY\",\n",
    "                        \"items\": {\"type\": \"STRING\"}\n",
    "                      }\n",
    "                    }\n",
    "                  },\n",
    "                  \"required\": [\"tool_uses\", \"intermediate_responses\"]\n",
    "                }\n",
    "              },\n",
    "              \"required\": [\"invocation_id\", \"user_content\", \"final_response\", \"intermediate_data\"]\n",
    "            }\n",
    "          },\n",
    "          \"session_input\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "              \"app_name\": {\"type\": \"STRING\"},\n",
    "              \"user_id\": {\"type\": \"STRING\"},\n",
    "              \"state\": {\"type\": \"OBJECT\"}\n",
    "            },\n",
    "            \"required\": [\"app_name\", \"user_id\", \"state\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"eval_id\", \"conversation\", \"session_input\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"eval_set_id\", \"name\", \"description\", \"eval_cases\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c26b7-9fd3-4e39-9c2a-3cc28ca62d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init client\n",
    "client = genai.Client(vertexai=True, location=\"global\", project = \"matt-demos\") # TODO: CHANGE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fc2d7-6f4d-483c-ab8e-e54a581c508e",
   "metadata": {},
   "source": [
    "### Calculate & Verify Token Count\n",
    "This cell calculates the total token count for the prompt, CSV data, and system prompt to ensure the combined input is within the model's context limit. It provides a detailed breakdown and a final validation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575ec06-6fab-408c-83c7-53643d136693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('chats_with_sessions.csv')\n",
    "csv_content = df.to_csv(index=False)\n",
    "\n",
    "# Count tokens for each part\n",
    "def count_tokens_safe(text, model_name):\n",
    "    \"\"\"Count tokens with error handling\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        response = model.count_tokens(text)\n",
    "        return response.total_tokens\n",
    "    except Exception as e:\n",
    "        # Fallback to character estimation if API fails\n",
    "        return len(str(text)) // 3\n",
    "\n",
    "# Token counting\n",
    "prompt_tokens = count_tokens_safe(create_evalset_prompt, model_name=model)\n",
    "csv_tokens = count_tokens_safe(csv_content, model_name=model)\n",
    "sys_prompt_tokens = count_tokens_safe(sys_prompt, model_name=model)\n",
    "total_input_tokens = prompt_tokens + csv_tokens + sys_prompt_tokens\n",
    "\n",
    "print(f\"Token Analysis:\")\n",
    "print(f\"Prompt tokens:      {prompt_tokens:8,}\")\n",
    "print(f\"CSV data tokens:    {csv_tokens:8,}\")\n",
    "print(f\"System prompt:      {sys_prompt_tokens:8,}\")\n",
    "print(f\"Total input tokens: {total_input_tokens:8,}\")\n",
    "print(f\"Context limit:      {2_000_000:8,}\")\n",
    "print(f\"Usage:              {(total_input_tokens/2_000_000)*100:7.1f}%\")\n",
    "\n",
    "# Check if within limits\n",
    "if total_input_tokens > 2_000_000:\n",
    "    print(\"WARNING: Exceeds context limit!\")\n",
    "else:\n",
    "    print(\"OK: Within context limits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a59423-9460-4b80-b437-734d54f4dc47",
   "metadata": {},
   "source": [
    "### **Configure Model for Structured JSON Output**\n",
    "\n",
    "This cell prepares and configures a request to a generative AI model, specifically instructing it to return a response in a structured JSON format.\n",
    "\n",
    "1.  **Load and Prepare Data**: It reads chat logs from the `chats_with_sessions.csv` file into a pandas DataFrame and then converts this data into a single string variable (`csv_content`).\n",
    "\n",
    "2.  **Construct the Prompt**: It creates the full prompt (`contents`) that will be sent to the model. This prompt combines a set of instructions (`create_evalset_prompt`) with the chat log data.\n",
    "\n",
    "3.  **Define Generation Parameters**: It sets up a detailed `GenerateContentConfig` to control the model's behavior:\n",
    "    * Sets a low `temperature` for more deterministic and less random outputs.\n",
    "    * Provides the model with a `GoogleSearch` tool.\n",
    "    * Assigns a `system_instruction` to guide the model's overall function.\n",
    "    * **Crucially, it specifies a `response_schema` and sets the `response_mime_type` to `\"application/json\"`, which forces the model to generate its output in a predefined JSON structure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b4f40-f18a-460f-83a3-d3808f6d9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [\n",
    "    types.Content(role=\"user\", parts=[\n",
    "        types.Part.from_text(text=create_evalset_prompt),\n",
    "        types.Part.from_text(text=f\"\\CHAT LOGS:\\n{csv_content}\")]\n",
    "                 )\n",
    "]\n",
    "# Enable tools\n",
    "tools = [types.Tool(google_search=types.GoogleSearch()),]\n",
    "\n",
    "# Config\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "  temperature = 0,\n",
    "  top_p = 0.95,\n",
    "  seed = 1000,\n",
    "  max_output_tokens = 65535,\n",
    "  safety_settings = safety_settings,\n",
    "  tools = tools,\n",
    "  system_instruction=[\n",
    "    types.Part.from_text(text=sys_prompt)],\n",
    "  thinking_config=types.ThinkingConfig(thinking_budget=-1,),\n",
    "  response_schema=response_schema,\n",
    "  response_mime_type=\"application/json\"  # Ensure JSON output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc509c-4f30-470d-b9c1-a5b2d920a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate all chunks. \n",
    "full_response = \"\"\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=model,\n",
    "    contents=contents,\n",
    "    config=generate_content_config,\n",
    "):\n",
    "    if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:\n",
    "        continue\n",
    "    #print(chunk.text, end=\"\")\n",
    "    full_response += chunk.text\n",
    "\n",
    "# Save to JSON file\n",
    "try:\n",
    "    # Parse the response as JSON to validate it\n",
    "    response_json = json.loads(full_response)\n",
    "    \n",
    "    # Save to file\n",
    "    with open('evalset.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(response_json, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nResponse saved to gemini_response.json\")\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\nError parsing JSON: {e}\")\n",
    "    # Save as raw text if JSON parsing fails\n",
    "    with open('gemini_response_raw.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(full_response)\n",
    "    print(\"Raw response saved to gemini_response_raw.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3999f-d68e-46d8-8c13-54a4912056e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90e13d-23de-4ee3-885a-51c53f8aff21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b700fa-2e25-4432-9bee-9ae3a77923b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
